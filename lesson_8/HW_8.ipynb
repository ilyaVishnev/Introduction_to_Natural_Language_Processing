{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cuXvnskTZPbd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sHoL4likZ7ux",
    "outputId": "c44daf42-c96c-454e-ede6-03cf774806af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "o5IPZtB2aCmI"
   },
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw] #долгая Каноническая форма слова (например, форма единственного числа, именительного падежа для существительных)\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VMMrtH--aUzm"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "#import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, Conv2D, GlobalMaxPool1D, concatenate, Flatten, add, MaxPool1D, RepeatVector\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Masking, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, TimeDistributed, AveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_-mOllPbaduF"
   },
   "outputs": [],
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fy2xqMn-cK1t"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train) #Текст в последовательности\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length) #Эта функция преобразует список (длиной num_samples) последовательностей (списков целых чисел) в двумерный массив Numpy \n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CShnSo8KcbjN"
   },
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XUBIUd0ny5-"
   },
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbVA54XnnyQm",
    "outputId": "31efc789-e37b-4b28-e01d-877c16f30d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 126s 356ms/step - loss: 0.6417 - accuracy: 0.6030 - val_loss: 0.5189 - val_accuracy: 0.7336\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 194s 608ms/step - loss: 0.4104 - accuracy: 0.8191 - val_loss: 0.5099 - val_accuracy: 0.7517\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 163s 510ms/step - loss: 0.1921 - accuracy: 0.9283 - val_loss: 0.6558 - val_accuracy: 0.7382\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 131s 411ms/step - loss: 0.0982 - accuracy: 0.9655 - val_loss: 0.7996 - val_accuracy: 0.7349\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 193s 605ms/step - loss: 0.0623 - accuracy: 0.9786 - val_loss: 0.9854 - val_accuracy: 0.7252\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 178s 559ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 1.0549 - val_accuracy: 0.7268\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 118s 371ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 1.1280 - val_accuracy: 0.7236\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 116s 365ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 1.2356 - val_accuracy: 0.7238\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 119s 374ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 1.3427 - val_accuracy: 0.7197\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 114s 357ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 1.4157 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "model_name = 'RNN'\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
    "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
    "              output_dim=30, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
    "model.add(SimpleRNN(32, recurrent_dropout=0.2, return_sequences=True)) #возвращать всю последовательность выходных данных для каждого элемента (по одному вектору на каждый шаг)\n",
    "model.add(SimpleRNN(32, recurrent_dropout=0.2))#отбрасывание линейных значений повторов 0.2\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#early_stopping=EarlyStopping(monitor='val_loss') #Класс EarlyStopping Остановить обучение, когда отслеживаемая метрика перестанет улучшаться \n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs/'+ model_name, \n",
    "    write_graph=False, update_freq=100, profile_batch=0)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwM8pG39PIJr",
    "outputId": "2bc41fba-1ac2-47b7-e119-64af7fb4fa02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 5s 100ms/step - loss: 1.4475 - accuracy: 0.7006\n",
      "\n",
      "\n",
      "Test score: 1.4474695920944214\n",
      "Test accuracy: 0.7005687355995178\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbjZM-FAq6oF"
   },
   "source": [
    "### CNN -> RNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "X-OfjmHoosEm"
   },
   "outputs": [],
   "source": [
    "model_name = 'CNN -> RNN'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
    "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
    "              output_dim=64, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
    "model.add(Conv1D(128, 3, activation='relu', padding=\"same\"))\n",
    "model.add(SimpleRNN(64, recurrent_dropout=0.2)) #отбрасывание линейных значений повторов 0.2\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYacBPbPrydf",
    "outputId": "18b0a096-35a6-4767-834e-2f3b2fb8ff88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 270s 800ms/step - loss: 0.5938 - accuracy: 0.6573 - val_loss: 0.5018 - val_accuracy: 0.7520\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 185s 579ms/step - loss: 0.3443 - accuracy: 0.8544 - val_loss: 0.5392 - val_accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 190s 594ms/step - loss: 0.1416 - accuracy: 0.9479 - val_loss: 0.7532 - val_accuracy: 0.7368\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 174s 544ms/step - loss: 0.0646 - accuracy: 0.9773 - val_loss: 0.9039 - val_accuracy: 0.7302\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 157s 491ms/step - loss: 0.0339 - accuracy: 0.9883 - val_loss: 1.2097 - val_accuracy: 0.7297\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 148s 465ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 1.3958 - val_accuracy: 0.7219\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 150s 471ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 1.5766 - val_accuracy: 0.7249\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 200s 627ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 1.6606 - val_accuracy: 0.7252\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 292s 918ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 1.9737 - val_accuracy: 0.7238\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 298s 935ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.8886 - val_accuracy: 0.7206\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3Tygx31rMQo"
   },
   "source": [
    "### RNN -> CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "L2msS2UpwgcO"
   },
   "outputs": [],
   "source": [
    "model_name = 'RNN -> CNN'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
    "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
    "              output_dim=64, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
    "model.add(SimpleRNN(64, recurrent_dropout=0.2, return_sequences=True)) #отбрасывание линейных значений повторов 0.2\n",
    "# model.add(RepeatVector(32))\n",
    "model.add(Conv1D(128, 3, activation='relu', padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OK6QAuP6zxm_",
    "outputId": "caceb641-3a7a-4cd6-c729-9753265a42fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 398s 1s/step - loss: 0.6309 - accuracy: 0.6058 - val_loss: 0.5134 - val_accuracy: 0.7423\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 381s 1s/step - loss: 0.4022 - accuracy: 0.8280 - val_loss: 0.4972 - val_accuracy: 0.7514\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 410s 1s/step - loss: 0.1681 - accuracy: 0.9406 - val_loss: 0.6628 - val_accuracy: 0.7328\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 369s 1s/step - loss: 0.0687 - accuracy: 0.9787 - val_loss: 0.9156 - val_accuracy: 0.7284\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 320s 1s/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 1.3654 - val_accuracy: 0.7271\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 232s 728ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 1.6010 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 224s 701ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 1.8883 - val_accuracy: 0.7265\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 162s 506ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.7778 - val_accuracy: 0.7208\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 192s 601ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 1.8091 - val_accuracy: 0.7197\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 260s 817ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 2.0808 - val_accuracy: 0.7184\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOIWvCOlcggH"
   },
   "source": [
    "#LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bR_ROb13crym",
    "outputId": "a066d2e0-2c31-4ae2-ff57-adf102028386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 269s 786ms/step - loss: 0.5536 - accuracy: 0.7081 - val_loss: 0.4974 - val_accuracy: 0.7537\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 206s 646ms/step - loss: 0.3229 - accuracy: 0.8669 - val_loss: 0.5343 - val_accuracy: 0.7478\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 203s 637ms/step - loss: 0.1538 - accuracy: 0.9427 - val_loss: 0.6857 - val_accuracy: 0.7377\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 244s 764ms/step - loss: 0.0898 - accuracy: 0.9676 - val_loss: 0.8755 - val_accuracy: 0.7325\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 242s 758ms/step - loss: 0.0634 - accuracy: 0.9772 - val_loss: 0.9870 - val_accuracy: 0.7298\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 246s 771ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 1.1033 - val_accuracy: 0.7292\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 268s 840ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 1.3783 - val_accuracy: 0.7196\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 293s 919ms/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 1.3291 - val_accuracy: 0.7251\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 330s 1s/step - loss: 0.0268 - accuracy: 0.9895 - val_loss: 1.5103 - val_accuracy: 0.7216\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 360s 1s/step - loss: 0.0241 - accuracy: 0.9906 - val_loss: 1.5755 - val_accuracy: 0.7193\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count, #это размер словаря в текстовых данных\n",
    "              input_length=training_length, #это длина входных последовательностей, которую вы бы определили для любого входного слоя модели Keras\n",
    "              output_dim=30, #это размер векторного пространства, в которое будут встроены слова. Он определяет размер выходных векторов из этого слоя для каждого слова. Например, это может быть 32 или 100 или даже больше.\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0)) #Маскирует последовательность,используя значение маски для пропуска таймфреймов\n",
    "model.add(LSTM(64, recurrent_dropout=0.2)) #отбрасывание линейных значений повторов 0.2\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuI_FZFYc6_D",
    "outputId": "aa64e242-82e3-430b-a1a8-2260419382eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 5s 104ms/step - loss: 1.6871 - accuracy: 0.7082\n",
      "\n",
      "\n",
      "Test score: 1.687084674835205\n",
      "Test accuracy: 0.7082396745681763\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSAVoeAeJpZu"
   },
   "source": [
    "#### Получим предсказание тональности твита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSkPXrOqBrOu",
    "outputId": "18d3fc2e-f834-4520-d163-f76b4419eb87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['тектоника рельефсамый ужасный мир мучение',\n",
       "       'ходить запускать шар желание насна получиться хрен они',\n",
       "       'хотеть лето ради направить ноготь яркий лак', ...,\n",
       "       'rt killgayslut yournovocaine привеееть муд черта сэмми',\n",
       "       'настроение вроде нормальный плакать хотеться',\n",
       "       'зайти сон девчонкампока мыть посудунастя фоткаться httptcokinexudtuh'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QT8cKwEeGA0V"
   },
   "outputs": [],
   "source": [
    "#предобработка текста для предсказания модели\n",
    "def preprocess_text_for_prediction(txt):\n",
    "  txt = preprocess_text(txt)\n",
    "  txt = tokenizer.texts_to_sequences([txt])\n",
    "  matr_txt = pad_sequences(txt, maxlen=training_length)\n",
    "  mart_txt = matr_txt.reshape(1, -1)\n",
    "  return matr_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgxWDGaVKjx2",
    "outputId": "db21f0dd-a177-40a7-8dfd-8ea0b7c98ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.390437e-05]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    [preprocess_text_for_prediction('тектоника рельефсамый ужасный мир мучение')],\n",
    "    batch_size=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5McsV1HKaw2",
    "outputId": "1440147f-f55d-4262-f4df-ae0492b2cce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0178717]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    [preprocess_text_for_prediction('Люблю смотреть на звезды')],\n",
    "    batch_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YQrd7Cyv07O",
    "outputId": "fd22ee9f-8a10-4ca6-93e1-9e55e418ba84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9954847]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    [preprocess_text_for_prediction('Великолепно!')], \n",
    "    batch_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYcOmFCIK7FP"
   },
   "source": [
    "Вроде что-то определяет "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0V7R8osLKpG"
   },
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wrYzxF3gdCET"
   },
   "outputs": [],
   "source": [
    "model_name = 'Bidirectional LSTM'\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "x =     Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True)(inputs)\n",
    "\n",
    "xbi = Bidirectional(LSTM(15, return_sequences=True))(x) #Двунаправленный\n",
    "x = add([x, xbi])\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTFmgM4jdElR",
    "outputId": "3055016f-c21d-4099-c8b0-cc462fd4d8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 292s 740ms/step - loss: 0.5524 - accuracy: 0.7044 - val_loss: 0.4875 - val_accuracy: 0.7592\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 189s 593ms/step - loss: 0.2940 - accuracy: 0.8801 - val_loss: 0.5426 - val_accuracy: 0.7534\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 204s 639ms/step - loss: 0.1194 - accuracy: 0.9571 - val_loss: 0.7136 - val_accuracy: 0.7386\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 180s 564ms/step - loss: 0.0633 - accuracy: 0.9782 - val_loss: 0.8822 - val_accuracy: 0.7301\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 191s 599ms/step - loss: 0.0394 - accuracy: 0.9868 - val_loss: 1.0846 - val_accuracy: 0.7274\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 186s 584ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 1.1997 - val_accuracy: 0.7225\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 152s 474ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 1.3770 - val_accuracy: 0.7178\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 153s 479ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.4580 - val_accuracy: 0.7159\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 157s 491ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.6666 - val_accuracy: 0.7155\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 140s 438ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.7399 - val_accuracy: 0.7141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_1 = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ijjl17HMdIEW",
    "outputId": "1c327d4e-2ce2-4955-af36-55aae7f01f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 9s 192ms/step - loss: 1.7228 - accuracy: 0.7105\n",
      "\n",
      "\n",
      "Test score: 1.7227580547332764\n",
      "Test accuracy: 0.7104880213737488\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRRMrWwGdPww"
   },
   "source": [
    "#CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Gq4WzNJCdVDH"
   },
   "outputs": [],
   "source": [
    "model_name = 'CNN'\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=100,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "#model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dbhcZUWdYDy",
    "outputId": "342f5478-7012-4267-adb5-b68baf403592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 237s 720ms/step - loss: 0.5384 - accuracy: 0.7163 - val_loss: 0.4818 - val_accuracy: 0.7601\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 225s 705ms/step - loss: 0.2524 - accuracy: 0.8978 - val_loss: 0.5532 - val_accuracy: 0.7473\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 212s 664ms/step - loss: 0.0664 - accuracy: 0.9769 - val_loss: 0.7382 - val_accuracy: 0.7376\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 191s 599ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.9164 - val_accuracy: 0.7369\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 193s 606ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 1.0737 - val_accuracy: 0.7349\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 212s 664ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 1.1917 - val_accuracy: 0.7371\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 221s 692ms/step - loss: 7.1542e-04 - accuracy: 0.9999 - val_loss: 1.2846 - val_accuracy: 0.7336\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 211s 660ms/step - loss: 3.3201e-04 - accuracy: 1.0000 - val_loss: 1.3779 - val_accuracy: 0.7325\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 389s 1s/step - loss: 2.2727e-04 - accuracy: 1.0000 - val_loss: 1.4138 - val_accuracy: 0.7355\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 353s 1s/step - loss: 2.0834e-04 - accuracy: 1.0000 - val_loss: 1.4720 - val_accuracy: 0.7357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYK0THNEdasw",
    "outputId": "5cde2016-a7c2-46f2-fc06-05a651d3cebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 3s 70ms/step - loss: 1.7641 - accuracy: 0.7192\n",
      "\n",
      "\n",
      "Test score: 1.764114499092102\n",
      "Test accuracy: 0.7191729545593262\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfLpVUccddBm"
   },
   "source": [
    "#CNN -> LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rX1KIsl0dgEm",
    "outputId": "193807c1-dca0-409b-f157-6b1a02fc4f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 412s 1s/step - loss: 0.5475 - accuracy: 0.7111 - val_loss: 0.4865 - val_accuracy: 0.7577\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 325s 1s/step - loss: 0.2979 - accuracy: 0.8770 - val_loss: 0.5426 - val_accuracy: 0.7425\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 315s 986ms/step - loss: 0.1360 - accuracy: 0.9498 - val_loss: 0.7235 - val_accuracy: 0.7362\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 346s 1s/step - loss: 0.0758 - accuracy: 0.9718 - val_loss: 0.8895 - val_accuracy: 0.7329\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 372s 1s/step - loss: 0.0458 - accuracy: 0.9833 - val_loss: 1.2123 - val_accuracy: 0.7311\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 414s 1s/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 1.3137 - val_accuracy: 0.7270\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 395s 1s/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 1.4388 - val_accuracy: 0.7247\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 395s 1s/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 1.6492 - val_accuracy: 0.7239\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 409s 1s/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 1.8558 - val_accuracy: 0.7219\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 335s 1s/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.9971 - val_accuracy: 0.7226\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CNN'\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3, activation='relu', padding=\"same\"))\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1cly0CPdizk",
    "outputId": "e729ae05-8fcb-4a48-b442-5934717fb137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/45 [====>.........................] - ETA: 8s - loss: 2.1082 - accuracy: 0.7075"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 9s 191ms/step - loss: 2.0548 - accuracy: 0.7151\n",
      "\n",
      "\n",
      "Test score: 2.05476975440979\n",
      "Test accuracy: 0.7151170372962952\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79Vbxz1QdmGl"
   },
   "source": [
    "#LSTM -> CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbYV4991dqG2",
    "outputId": "617fddc5-103f-49e5-8fc8-d22141a66b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "319/319 [==============================] - 319s 953ms/step - loss: 0.5530 - accuracy: 0.7059 - val_loss: 0.4867 - val_accuracy: 0.7597\n",
      "Epoch 2/10\n",
      "319/319 [==============================] - 266s 834ms/step - loss: 0.3091 - accuracy: 0.8724 - val_loss: 0.5460 - val_accuracy: 0.7433\n",
      "Epoch 3/10\n",
      "319/319 [==============================] - 237s 743ms/step - loss: 0.1473 - accuracy: 0.9454 - val_loss: 0.6929 - val_accuracy: 0.7339\n",
      "Epoch 4/10\n",
      "319/319 [==============================] - 242s 759ms/step - loss: 0.0889 - accuracy: 0.9685 - val_loss: 0.8381 - val_accuracy: 0.7304\n",
      "Epoch 5/10\n",
      "319/319 [==============================] - 234s 735ms/step - loss: 0.0590 - accuracy: 0.9786 - val_loss: 1.1037 - val_accuracy: 0.7233\n",
      "Epoch 6/10\n",
      "319/319 [==============================] - 237s 743ms/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 1.2339 - val_accuracy: 0.7266\n",
      "Epoch 7/10\n",
      "319/319 [==============================] - 242s 759ms/step - loss: 0.0324 - accuracy: 0.9876 - val_loss: 1.3958 - val_accuracy: 0.7235\n",
      "Epoch 8/10\n",
      "319/319 [==============================] - 238s 745ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 1.5919 - val_accuracy: 0.7265\n",
      "Epoch 9/10\n",
      "319/319 [==============================] - 238s 746ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 1.6815 - val_accuracy: 0.7216\n",
      "Epoch 10/10\n",
      "319/319 [==============================] - 229s 719ms/step - loss: 0.0187 - accuracy: 0.9929 - val_loss: 1.8589 - val_accuracy: 0.7217\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM -> CNN'\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Conv1D(64, 3, activation='relu', padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir='logs/'+ model_name, \n",
    "#     write_graph=False, update_freq=100, profile_batch=0)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)#,\n",
    "                    #callbacks=[tensorboard_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biA22UYDdtWQ",
    "outputId": "c52a580a-4234-4786-e73e-7f93cea9d0d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 6s 132ms/step - loss: 1.9735 - accuracy: 0.7129\n",
      "\n",
      "\n",
      "Test score: 1.9734731912612915\n",
      "Test accuracy: 0.7129127383232117\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5uJznLqdwfi"
   },
   "source": [
    "Все модели показали относительно одинаковые результаты, похоже что сети переобучаются."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
